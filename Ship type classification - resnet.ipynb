{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import platform\n",
    "python_v = platform.python_version()\n",
    "print (python_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saghar/.virtualenvs/02ML/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wget\n",
    "import zipfile\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def download_dataset(url, path='./'):\n",
    "    print(\"  Downloading dataset from\", url)\n",
    "    return wget.download(url)\n",
    "\n",
    "def unzip(filename, path='./'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        z = zipfile.ZipFile(f)\n",
    "        print(\"  Unzipping file\", filename)\n",
    "        for name in z.namelist():\n",
    "            print(\"    Extracting file\", name)\n",
    "            z.extract(name,path)\n",
    "        \n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "#only the first time\n",
    "#url = 'https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip'\n",
    "#filename = download_dataset(url, path='./')\n",
    "#unzip(filename, path='./')\n",
    "\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# Let's check the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dogImages/train/095.Kuvasz/Kuvasz_06442.jpg',\n",
       "       'dogImages/train/057.Dalmatian/Dalmatian_04054.jpg',\n",
       "       'dogImages/train/088.Irish_water_spaniel/Irish_water_spaniel_06014.jpg',\n",
       "       ..., 'dogImages/train/029.Border_collie/Border_collie_02069.jpg',\n",
       "       'dogImages/train/046.Cavalier_king_charles_spaniel/Cavalier_king_charles_spaniel_03261.jpg',\n",
       "       'dogImages/train/048.Chihuahua/Chihuahua_03416.jpg'], dtype='<U99')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6680/6680 [00:43<00:00, 154.68it/s]\n",
      "100%|██████████| 835/835 [01:33<00:00,  8.94it/s]\n",
      "100%|██████████| 836/836 [00:11<00:00, 75.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune a pre-trained model (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "\n",
    "def extract_Resnet50(file_paths):\n",
    "    tensors = paths_to_tensor(file_paths).astype('float32')\n",
    "    preprocessed_input = preprocess_input_resnet50(tensors)\n",
    "    return ResNet50(weights='imagenet', include_top=False).predict(preprocessed_input, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6680/6680 [01:35<00:00, 70.05it/s]\n",
      "100%|██████████| 835/835 [00:15<00:00, 55.07it/s]\n",
      "100%|██████████| 836/836 [00:13<00:00, 61.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 shape (1, 1, 2048)\n"
     ]
    }
   ],
   "source": [
    "train_resnet50 = extract_Resnet50(train_files)\n",
    "valid_resnet50 = extract_Resnet50(valid_files)\n",
    "test_resnet50 = extract_Resnet50(test_files)\n",
    "print(\"Resnet50 shape\", train_resnet50.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the last layers for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1048576   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 640)               327680    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 640)               2560      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 133)               85253     \n",
      "=================================================================\n",
      "Total params: 1,466,117\n",
      "Trainable params: 1,463,813\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "def input_branch(input_shape=None):\n",
    "    \n",
    "    size = int(input_shape[2] / 4)\n",
    "    \n",
    "    branch_input = Input(shape=input_shape)\n",
    "    branch = GlobalAveragePooling2D()(branch_input)\n",
    "    branch = Dense(size, use_bias=False, kernel_initializer='uniform')(branch)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branch = Activation(\"relu\")(branch)\n",
    "    return branch, branch_input\n",
    "\n",
    "resnet50_branch, resnet50_input = input_branch(input_shape=(1, 1, 2048))\n",
    "net = Dropout(0.3)(resnet50_branch)\n",
    "net = Dense(640, use_bias=False, kernel_initializer='uniform')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "net = Dropout(0.3)(net)\n",
    "net = Dense(133, kernel_initializer='uniform', activation=\"softmax\")(net)\n",
    "\n",
    "model = Model(inputs=[resnet50_input], outputs=[net])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and fit the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/10\n",
      "6680/6680 [==============================] - 32s 5ms/step - loss: 1.6179 - acc: 0.5540 - val_loss: 0.8094 - val_acc: 0.7521\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80943, saving model to saved_models/bestmodel.hdf5\n",
      "Epoch 2/10\n",
      "6680/6680 [==============================] - 30s 5ms/step - loss: 1.3993 - acc: 0.6124 - val_loss: 0.7210 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80943 to 0.72104, saving model to saved_models/bestmodel.hdf5\n",
      "Epoch 3/10\n",
      "6680/6680 [==============================] - 30s 5ms/step - loss: 1.2926 - acc: 0.6446 - val_loss: 0.6950 - val_acc: 0.7749\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.72104 to 0.69498, saving model to saved_models/bestmodel.hdf5\n",
      "Epoch 4/10\n",
      "6680/6680 [==============================] - 31s 5ms/step - loss: 1.1550 - acc: 0.6692 - val_loss: 0.6824 - val_acc: 0.7796\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69498 to 0.68243, saving model to saved_models/bestmodel.hdf5\n",
      "Epoch 5/10\n",
      "6680/6680 [==============================] - 31s 5ms/step - loss: 1.1361 - acc: 0.6910 - val_loss: 0.6220 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68243 to 0.62200, saving model to saved_models/bestmodel.hdf5\n",
      "Epoch 6/10\n",
      "6680/6680 [==============================] - 31s 5ms/step - loss: 1.0363 - acc: 0.7078 - val_loss: 0.6340 - val_acc: 0.7964\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "6680/6680 [==============================] - 31s 5ms/step - loss: 1.0197 - acc: 0.7171 - val_loss: 0.6143 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62200 to 0.61433, saving model to saved_models/bestmodel.hdf5\n",
      "Epoch 8/10\n",
      "6680/6680 [==============================] - 31s 5ms/step - loss: 1.0124 - acc: 0.7234 - val_loss: 0.6340 - val_acc: 0.7952\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "6680/6680 [==============================] - 31s 5ms/step - loss: 0.9492 - acc: 0.7347 - val_loss: 0.6154 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "6680/6680 [==============================] - 31s 5ms/step - loss: 0.9094 - acc: 0.7567 - val_loss: 0.6047 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61433 to 0.60471, saving model to saved_models/bestmodel.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae19957198>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/bestmodel.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit([train_resnet50], train_targets, \n",
    "          validation_data=([valid_resnet50], valid_targets),\n",
    "          epochs=10, batch_size=4, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 83.2536%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('saved_models/bestmodel.hdf5')\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = model.predict([test_resnet50])\n",
    "breed_predictions = [np.argmax(prediction) for prediction in predictions]\n",
    "breed_true_labels = [np.argmax(true_label) for true_label in test_targets]\n",
    "print('Test accuracy: %.4f%%' % (accuracy_score(breed_true_labels, breed_predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
